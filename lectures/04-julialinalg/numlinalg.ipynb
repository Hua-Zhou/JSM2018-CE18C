{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Julia:-Numerical-Linear-Algebra\" data-toc-modified-id=\"Julia:-Numerical-Linear-Algebra-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Julia: Numerical Linear Algebra</a></div><div class=\"lev2 toc-item\"><a href=\"#Numerical-linear-algebra:-introduction\" data-toc-modified-id=\"Numerical-linear-algebra:-introduction-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Numerical linear algebra: introduction</a></div><div class=\"lev2 toc-item\"><a href=\"#BLAS\" data-toc-modified-id=\"BLAS-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>BLAS</a></div><div class=\"lev2 toc-item\"><a href=\"#Memory-hierarchy-and-level-3-fraction\" data-toc-modified-id=\"Memory-hierarchy-and-level-3-fraction-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Memory hierarchy and level-3 fraction</a></div><div class=\"lev2 toc-item\"><a href=\"#Effect-of-data-layout\" data-toc-modified-id=\"Effect-of-data-layout-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Effect of data layout</a></div><div class=\"lev2 toc-item\"><a href=\"#Avoid-memory-allocation:-some-examples\" data-toc-modified-id=\"Avoid-memory-allocation:-some-examples-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Avoid memory allocation: some examples</a></div><div class=\"lev3 toc-item\"><a href=\"#Transposing-matrix-is-expensive\" data-toc-modified-id=\"Transposing-matrix-is-expensive-151\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Transposing matrix is expensive</a></div><div class=\"lev2 toc-item\"><a href=\"#Sparse-linear-algebra\" data-toc-modified-id=\"Sparse-linear-algebra-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Sparse linear algebra</a></div><div class=\"lev2 toc-item\"><a href=\"#Iterative-methods-for-linear-algebra\" data-toc-modified-id=\"Iterative-methods-for-linear-algebra-17\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Iterative methods for linear algebra</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia: Numerical Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical linear algebra occupies much of statistical computing. This notebook gives a quick overview of linear algebra in Julia.\n",
    "\n",
    "Machine information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 0.6.4\n",
      "Commit 9d11f62bcb (2018-07-09 19:09 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin14.5.0)\n",
      "  CPU: Intel(R) Core(TM) i7-6920HQ CPU @ 2.90GHz\n",
      "  WORD_SIZE: 64\n",
      "  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell MAX_THREADS=16)\n",
      "  LAPACK: libopenblas64_\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-3.9.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical linear algebra: introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Topics in numerical linear algebra: \n",
    "    - BLAS: vector operations, matrix-vector multiplications, matrix-matrix multiplications  \n",
    "    - solve linear equations $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$\n",
    "    - regression computations $\\mathbf{X}^T \\mathbf{X} \\beta = \\mathbf{X}^T \\mathbf{y}$  \n",
    "    - eigen-problems $\\mathbf{A} \\mathbf{x} = \\lambda \\mathbf{x}$  \n",
    "    - generalized eigen-problems $\\mathbf{A} \\mathbf{x} = \\lambda \\mathbf{B} \\mathbf{x}$  \n",
    "    - singular value decompositions $\\mathbf{A} = \\mathbf{U} \\Sigma \\mathbf{V}^T$  \n",
    "    - iterative methods for numerical linear algebra    \n",
    "\n",
    "* Except for the iterative methods, most of these numerical linear algebra tasks are implemented in the BLAS and LAPACK libraries. They form the **building blocks** of most statistical computing tasks (optimization, MCMC).\n",
    "\n",
    "* All high-level languages (R, Matlab, Julia) call BLAS and LAPACK for numerical linear algebra. \n",
    "    - Julia offers more flexibility by exposing interfaces to many BLAS/LAPACK subroutines directly. See documentation: [BLAS](https://docs.julialang.org/en/stable/stdlib/linalg/#BLAS-Functions-1), [LAPACK](https://docs.julialang.org/en/stable/stdlib/linalg/#LAPACK-Functions-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     14.346 ms (0.00% GC)\n",
       "  median time:      15.501 ms (0.00% GC)\n",
       "  mean time:        16.296 ms (6.26% GC)\n",
       "  maximum time:     21.766 ms (14.27% GC)\n",
       "  --------------\n",
       "  samples:          307\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "srand(123) # seed\n",
    "n = 1000\n",
    "A = randn(n, n)\n",
    "B = randn(n, n)\n",
    "@benchmark $A * $B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RCall.RObject{RCall.VecSxp}\n",
       "Unit: milliseconds\n",
       "                expr      min       lq     mean   median       uq      max\n",
       " `#JL`$A %*% `#JL`$B 602.5493 627.3499 646.7977 642.7177 658.0193 728.1404\n",
       " neval\n",
       "   100\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(microbenchmark)\n",
    "microbenchmark($A %*% $B)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base R is using a very outdated BLAS library. For this matrix multiplication example, we see a ~30-40 fold slowdown from Julia's OpenBLAS library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLAS\n",
    "\n",
    "* BLAS stands for _basic linear algebra subprograms_. \n",
    "\n",
    "* See [netlib](http://www.netlib.org/blas/) for a complete list of standardized BLAS functions.\n",
    "\n",
    "* There are many implementations of BLAS. \n",
    "    - [Netlib](http://www.netlib.org/blas/) provides a reference implementation  \n",
    "    - Matlab uses Intel's [MKL](https://software.intel.com/en-us/node/520724) (mathematical kernel libaries)  \n",
    "    - Julia uses [OpenBLAS](https://github.com/xianyi/OpenBLAS)  \n",
    "    - JuliaPro offers the option of using MKL\n",
    "\n",
    "* There are 3 levels of BLAS functions.\n",
    "    - [Level 1](http://www.netlib.org/blas/#_level_1): vector-vector operation\n",
    "    - [Level 2](http://www.netlib.org/blas/#_level_2): matrix-vector operation\n",
    "    - [Level 3](http://www.netlib.org/blas/#_level_3): matrix-matrix operation\n",
    "\n",
    "| Level | Example Operation                      | Name        | Dimension                                 | Flops |\n",
    "|-------|----------------------------------------|-------------|-------------------------------------------|-------|\n",
    "| 1     | $\\alpha \\gets \\mathbf{x}^T \\mathbf{y}$ | dot product | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ | $2n$  |\n",
    "|       | $\\mathbf{y} \\gets \\mathbf{y} + \\alpha \\mathbf{x}$ |  axpy           |  $\\alpha \\in \\mathbb{R}$, $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ |  $2n$    |\n",
    "| 2     | $\\mathbf{y} \\gets \\mathbf{y} + \\mathbf{A} \\mathbf{x}$ |  gaxpy           |  $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{x} \\in \\mathbb{R}^n$, $\\mathbf{y} \\in \\mathbb{R}^m$                                     |  $2mn$     |\n",
    "|       | $\\mathbf{A} \\gets \\mathbf{A} + \\mathbf{y} \\mathbf{x}^T$ | rank one update            |    $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{x} \\in \\mathbb{R}^n$, $\\mathbf{y} \\in \\mathbb{R}^m$                                       | $2mn$      |\n",
    "| 3     | $\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}$                                       |  matrix multiplication           |  $\\mathbf{A} \\in \\mathbb{R}^{m \\times p}$, $\\mathbf{B} \\in \\mathbb{R}^{p \\times n}$, $\\mathbf{C} \\in \\mathbb{R}^{m \\times n}$                                         | $2mnp$      |\n",
    "\n",
    "* Typical BLAS functions support single precision (S), double precision (D), complex (C), and double complex (Z). \n",
    "\n",
    "* Some operations _appear_ as level-3 but indeed are level-2.  \n",
    "    - A common operation in statistics is column scaling or row scaling\n",
    "    $$\n",
    "    \\begin{eqnarray*}\n",
    "        \\mathbf{A} &=& \\mathbf{A} \\mathbf{D} \\quad \\text{(column scaling)} \\\\\n",
    "        \\mathbf{A} &=& \\mathbf{D} \\mathbf{A} \\quad \\text{(row scaling)},\n",
    "    \\end{eqnarray*}\n",
    "    $$\n",
    "    where $\\mathbf{D}$ is diagonal.  \n",
    "    - These are essentially level-2 operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-element Array{Float64,1}:\n",
       " 0.763192\n",
       " 0.668759\n",
       " 0.709337\n",
       " 0.088416\n",
       " 0.289151\n",
       " 0.375468\n",
       " 0.437356\n",
       " 0.179474\n",
       " 0.122238\n",
       " 0.895783\n",
       " 0.332146\n",
       " 0.206425\n",
       " 0.747789\n",
       " ⋮       \n",
       " 0.484487\n",
       " 0.567484\n",
       " 0.75455 \n",
       " 0.703483\n",
       " 0.166205\n",
       " 0.754612\n",
       " 0.231834\n",
       " 0.769243\n",
       " 0.805681\n",
       " 0.553389\n",
       " 0.450904\n",
       " 0.814614"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "srand(123) # seed\n",
    "n = 2000\n",
    "A = rand(n, n)\n",
    "d = rand(n)  # d vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000×2000 Array{Float64,2}:\n",
       " 0.763192  0.0       0.0       0.0       …  0.0       0.0       0.0     \n",
       " 0.0       0.668759  0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.709337  0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.088416     0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0       …  0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0       …  0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " ⋮                                       ⋱                              \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0       …  0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0       …  0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.553389  0.0       0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.450904  0.0     \n",
       " 0.0       0.0       0.0       0.0          0.0       0.0       0.814614"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = diagm(d) # diagonal matrix with d as diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.52 MiB\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     107.945 ms (0.60% GC)\n",
       "  median time:      118.194 ms (3.17% GC)\n",
       "  mean time:        120.971 ms (4.45% GC)\n",
       "  maximum time:     173.536 ms (39.71% GC)\n",
       "  --------------\n",
       "  samples:          42\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is calling BLAS routine for matrix multiplication: O(n^3) flops\n",
    "@benchmark A * D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000×2000 Diagonal{Float64}:\n",
       " 0.763192   ⋅         ⋅         ⋅        …   ⋅         ⋅         ⋅      \n",
       "  ⋅        0.668759   ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅        0.709337   ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅        0.088416      ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅        …   ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅        …   ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       " ⋮                                       ⋱                              \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅        …   ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅        …   ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅           0.553389   ⋅         ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅        0.450904   ⋅      \n",
       "  ⋅         ⋅         ⋅         ⋅            ⋅         ⋅        0.814614"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Diagonal(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.52 MiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     8.891 ms (5.99% GC)\n",
       "  median time:      12.059 ms (32.07% GC)\n",
       "  mean time:        12.341 ms (33.58% GC)\n",
       "  maximum time:     94.327 ms (90.80% GC)\n",
       "  --------------\n",
       "  samples:          405\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current way for columnwise scaling: O(n^2) flops\n",
    "@benchmark A * Diagonal(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "*(A::<b>AbstractArray{T,2} where T</b>, D::<b>Diagonal</b>) at <a href=\"https://github.com/JuliaLang/julia/tree/9d11f62bcb124327831206089967f93020e84200/base/linalg/diagonal.jl#L152\" target=\"_blank\">linalg/diagonal.jl:152</a>"
      ],
      "text/plain": [
       "*(A::AbstractArray{T,2} where T, D::Diagonal) in Base.LinAlg at linalg/diagonal.jl:152"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which A * Diagonal(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.866 ms (0.00% GC)\n",
       "  median time:      10.123 ms (0.00% GC)\n",
       "  mean time:        10.787 ms (0.00% GC)\n",
       "  maximum time:     18.797 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          463\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-place: avoid allocate space for result\n",
    "@benchmark scale!(A, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory hierarchy and level-3 fraction\n",
    "\n",
    "> **Key to high performance is effective use of memory hierarchy. True on all architectures.**\n",
    "\n",
    "* Flop count is not the sole determinant of algorithm efficiency. Another important factor is data movement through the memory hierarchy.\n",
    "\n",
    "<img src=\"./macpro_inside.png\" width=\"400\" align=\"center\">\n",
    "\n",
    "<img src=\"./cpu_die.png\" width=\"400\" align=\"center\">  \n",
    "\n",
    "<img src=\"http://images.bit-tech.net/content_images/2007/11/the_secrets_of_pc_memory_part_1/hei.png\" width=\"400\" align=\"center\">\n",
    "\n",
    "* Numbers everyone should know\n",
    "\n",
    "| Operation                           | Time           |\n",
    "|-------------------------------------|----------------|\n",
    "| L1 cache reference                  | 0.5 ns         |\n",
    "| L2 cache reference                  | 7 ns           |\n",
    "| Main memory reference               | 100 ns         |\n",
    "| Read 1 MB sequentially from memory  | 250,000 ns     |\n",
    "| Read 1 MB sequentially from SSD     | 1,000,000 ns   |  \n",
    "| Read 1 MB sequentially from disk    | 20,000,000 ns  |\n",
    "\n",
    "\n",
    "<!-- | Operation                           | Time           | -->\n",
    "<!-- |-------------------------------------|----------------| -->\n",
    "<!-- | L1 cache reference                  | 0.5 ns         | -->\n",
    "<!-- | Branch mispredict                   | 5 ns           | -->\n",
    "<!-- | L2 cache reference                  | 7 ns           | -->\n",
    "<!-- | Mutex lock/unlock                   | 100 ns         | -->\n",
    "<!-- | Main memory reference               | 100 ns         | -->\n",
    "<!-- | Compress 1K bytes with Zippy        | 10,000 ns      | -->\n",
    "<!-- | Send 2K bytes over 1 Gbps network   | 20,000 ns      | -->\n",
    "<!-- | Read 1 MB sequentially from memory  | 250,000 ns     | -->\n",
    "<!-- | Round trip within same datacenter   | 500,000 ns     | -->\n",
    "<!-- | Disk seek                           | 10,000,000 ns  | -->\n",
    "<!-- | Read 1 MB sequentially from network | 10,000,000 ns  | -->\n",
    "<!-- | Read 1 MB sequentially from disk    | 30,000,000 ns  | -->\n",
    "<!-- | Send packet CA->Netherlands->CA     | 150,000,000 ns | -->\n",
    "\n",
    "   Source: <https://gist.github.com/jboner/2841832>  \n",
    "\n",
    "* For example, Xeon X5650 CPU has a theoretical throughput of 128 DP GFLOPS but a max memory bandwidth of 32GB/s.  \n",
    "\n",
    "* Can we keep CPU cores busy with enough deliveries of matrix data and ship the results to memory fast enough to avoid backlog?  \n",
    "Answer: use **high-level BLAS** as much as possible.\n",
    "\n",
    "| BLAS                                                           | Dimension                                                                           | Mem. Refs. | Flops  | Ratio |\n",
    "|----------------------------------------------------------------|-------------------------------------------------------------------------------------|------------|--------|-------|\n",
    "| Level 1: $\\mathbf{y} \\gets \\mathbf{y} + \\alpha \\mathbf{x}$     | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$                                           | $3n$       | $2n$   | 3:2   |\n",
    "| Level 2: $\\mathbf{y} \\gets \\mathbf{y} + \\mathbf{A} \\mathbf{x}$ | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$, $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ | $n^2$      | $2n^2$ | 1:2   |\n",
    "| Level 3: $\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}$ | $\\mathbf{A}, \\mathbf{B}, \\mathbf{C} \\in\\mathbb{R}^{n \\times n}$                    | $4n^2$     | $2n^3$ | 2:n |  \n",
    "\n",
    "* Higher level BLAS (3 or 2) make more effective use of arithmetic logic units (ALU) by keeping them busy. **Surface-to-volume** effect.  \n",
    "See [Dongarra slides](https://www.samsi.info/wp-content/uploads/2017/02/SAMSI-0217_Dongarra.pdf).\n",
    "\n",
    "<img src=\"./blas_throughput.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "* A distinction between LAPACK and LINPACK (older version of R uses LINPACK) is that LAPACK makes use of higher level BLAS as much as possible (usually by smart partitioning) to increase the so-called **level-3 fraction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of data layout\n",
    "\n",
    "* Data layout in memory affects algorithmic efficiency too. It is much faster to move chunks of data in memory than retrieving/writing scattered data.\n",
    "\n",
    "* Storage mode: **column-major** (Fortran, Matlab, R, Julia) vs **row-major** (C/C++).\n",
    "\n",
    "* **Cache line** is the minimum amount of cache which can be loaded and stored to memory.\n",
    "    - x86 CPUs: 64 bytes  \n",
    "    - ARM CPUS: 32 bytes\n",
    "\n",
    "<img src=\"https://patterns.eecs.berkeley.edu/wordpress/wp-content/uploads/2013/04/dense02.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "* Accessing column-major stored matrix by rows causes lots of **cache misses**.\n",
    "\n",
    "* Take matrix multiplication as an example \n",
    "$$ \n",
    "\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}, \\quad \\mathbf{A} \\in \\mathbb{R}^{m \\times p}, \\mathbf{B} \\in \\mathbb{R}^{p \\times n}, \\mathbf{C} \\in \\mathbb{R}^{m \\times n}.\n",
    "$$\n",
    "Assume the storage is column-major, such as in Julia. There are 6 variants of the algorithms according to the order in the triple loops. \n",
    "    - `jki` or `kji` looping:\n",
    "        ```julia\n",
    "        # inner most loop\n",
    "        for i = 1:m\n",
    "            C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "        end\n",
    "        ```  \n",
    "    - `ikj` or `kij` looping:\n",
    "        ```julia\n",
    "        # inner most loop        \n",
    "        for j = 1:n\n",
    "            C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "        end\n",
    "        ```  \n",
    "    - `ijk` or `jik` looping:\n",
    "        ```julia\n",
    "        # inner most loop        \n",
    "        for k = 1:p\n",
    "            C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "        end\n",
    "        ```\n",
    "* We pay attention to the innermost loop, where the vector calculation occurs. The associated **stride** when accessing the three matrices in memory (assuming column-major storage) is  \n",
    "\n",
    "| Variant        | A Stride | B Stride | C Stride |\n",
    "|----------------|----------|----------|----------|\n",
    "| $jki$ or $kji$ | Unit     | 0        | Unit     |\n",
    "| $ikj$ or $kij$ | 0        | Non-Unit | Non-Unit |\n",
    "| $ijk$ or $jik$ | Non-Unit | Unit     | 0        |       \n",
    "Apparently the variants $jki$ or $kji$ are preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    matmul_by_loop!(A, B, C, order)\n",
    "\n",
    "Overwrite `C` by `A * B`. `order` indicates the looping order for triple loop.\n",
    "\"\"\"\n",
    "function matmul_by_loop!(A::Matrix, B::Matrix, C::Matrix, order::String)\n",
    "    \n",
    "    m = size(A, 1)\n",
    "    p = size(A, 2)\n",
    "    n = size(B, 2)\n",
    "    fill!(C, 0)\n",
    "    \n",
    "    if order == \"jki\"\n",
    "        for j = 1:n, k = 1:p, i = 1:m\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if order == \"kji\"\n",
    "        for k = 1:p, j = 1:n, i = 1:m\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"ikj\"\n",
    "        for i = 1:m, k = 1:p, j = 1:n\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if order == \"kij\"\n",
    "        for k = 1:p, i = 1:m, j = 1:n\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"ijk\"\n",
    "        for i = 1:m, j = 1:n, k = 1:p\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"jik\"\n",
    "        for j = 1:n, i = 1:m, k = 1:p\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "srand(123) # seed\n",
    "m, n, p = 2000, 100, 2000\n",
    "A = rand(m, n)\n",
    "B = rand(n, p)\n",
    "C = zeros(m, p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $jki$ and $kji$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     447.619 ms (0.00% GC)\n",
       "  median time:      462.089 ms (0.00% GC)\n",
       "  mean time:        462.884 ms (0.00% GC)\n",
       "  maximum time:     474.856 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          11\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "@benchmark matmul_by_loop!($A, $B, $C, \"jki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     507.482 ms (0.00% GC)\n",
       "  median time:      520.323 ms (0.00% GC)\n",
       "  mean time:        522.122 ms (0.00% GC)\n",
       "  maximum time:     542.848 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark matmul_by_loop!($A, $B, $C, \"kji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ikj$ and $kij$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     2.549 s (0.00% GC)\n",
       "  median time:      2.560 s (0.00% GC)\n",
       "  mean time:        2.560 s (0.00% GC)\n",
       "  maximum time:     2.571 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark matmul_by_loop!($A, $B, $C, \"ikj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     2.860 s (0.00% GC)\n",
       "  median time:      2.903 s (0.00% GC)\n",
       "  mean time:        2.903 s (0.00% GC)\n",
       "  maximum time:     2.945 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark matmul_by_loop!($A, $B, $C, \"kij\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ijk$ and $jik$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     970.307 ms (0.00% GC)\n",
       "  median time:      982.267 ms (0.00% GC)\n",
       "  mean time:        994.529 ms (0.00% GC)\n",
       "  maximum time:     1.047 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          6\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark matmul_by_loop!($A, $B, $C, \"ijk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     954.502 ms (0.00% GC)\n",
       "  median time:      966.731 ms (0.00% GC)\n",
       "  mean time:        966.520 ms (0.00% GC)\n",
       "  maximum time:     976.980 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          6\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark matmul_by_loop!(A, B, C, \"ijk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Julia wraps BLAS library for matrix multiplication. We see BLAS library wins hands down (multi-threading, Strassen algorithm, higher level-3 fraction by block outer product)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "A_mul_B!<i>{T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64}}</i>(C::<b>Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}</b>, A::<b>Union{Union{Base.ReshapedArray{T,1,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,1}, SubArray{T,1,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}, Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}}</b>, B::<b>Union{Union{Base.ReshapedArray{T,1,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,1}, SubArray{T,1,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}, Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}}</b>) at <a href=\"https://github.com/JuliaLang/julia/tree/9d11f62bcb124327831206089967f93020e84200/base/linalg/matmul.jl#L148\" target=\"_blank\">linalg/matmul.jl:148</a>"
      ],
      "text/plain": [
       "A_mul_B!(C::Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}, A::Union{Union{Base.ReshapedArray{T,1,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,1}, SubArray{T,1,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}, Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}}, B::Union{Union{Base.ReshapedArray{T,1,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,1}, SubArray{T,1,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}, Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}}) where T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64} in Base.LinAlg at linalg/matmul.jl:148"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which A_mul_B!(C, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     7.216 ms (0.00% GC)\n",
       "  median time:      7.340 ms (0.00% GC)\n",
       "  mean time:        7.486 ms (0.00% GC)\n",
       "  maximum time:     10.680 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          667\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark A_mul_B!($C, $A, $B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.849 ms (0.00% GC)\n",
       "  median time:      5.351 ms (0.00% GC)\n",
       "  mean time:        5.417 ms (0.00% GC)\n",
       "  maximum time:     9.311 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          921\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark Base.LinAlg.BLAS.gemm!('N', 'N', 1.0, $A, $B, 1.0, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To appreciate the efforts in an optimized BLAS implementation such as OpenBLAS (evolved from GotoBLAS), see the [Quora question](https://www.quora.com/What-algorithm-does-BLAS-use-for-matrix-multiplication-Of-all-the-considerations-e-g-cache-popular-instruction-sets-Big-O-etc-which-one-turned-out-to-be-the-primary-bottleneck), especially the [video](https://youtu.be/JzNpKDW07rw). Bottomline is \n",
    "\n",
    "> **Get familiar with (good implementations of) BLAS/LAPACK and use them as much as possible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid memory allocation: some examples\n",
    "\n",
    "### Transposing matrix is expensive\n",
    "\n",
    "* In R, the command \n",
    "    ```R\n",
    "    t(A) %*% x\n",
    "    ```\n",
    "will first transpose `A` then perform matrix multiplication, causing unnecessary memory allocation\n",
    "- Julia is smart to avoid transposing matrix if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.94 KiB\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     87.899 μs (0.00% GC)\n",
       "  median time:      119.331 μs (0.00% GC)\n",
       "  mean time:        124.014 μs (0.00% GC)\n",
       "  maximum time:     378.717 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(123)\n",
    "\n",
    "n = 1000\n",
    "A = rand(n, n)\n",
    "x = rand(n)\n",
    "\n",
    "# dispatch to At_mul_B (and then to BLAS)\n",
    "# does *not* actually transpose the matrix\n",
    "@benchmark $A' * $x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "*<i>{T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64}, S}</i>(A::<b>Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}</b>, x::<b>Union{Base.ReshapedArray{S,1,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{S,1}, SubArray{S,1,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}</b>) at <a href=\"https://github.com/JuliaLang/julia/tree/9d11f62bcb124327831206089967f93020e84200/base/linalg/matmul.jl#L74\" target=\"_blank\">linalg/matmul.jl:74</a>"
      ],
      "text/plain": [
       "*(A::Union{Base.ReshapedArray{T,2,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{T,2}, SubArray{T,2,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}, x::Union{Base.ReshapedArray{S,1,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T}, DenseArray{S,1}, SubArray{S,1,A,I,L} where L} where I<:Tuple{Vararg{Union{Base.AbstractCartesianIndex, Int64, Range{Int64}},N} where N} where A<:Union{Base.ReshapedArray{T,N,A,MI} where MI<:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A<:Union{DenseArray, SubArray{T,N,P,I,true} where I<:Tuple{Union{Base.Slice, UnitRange},Vararg{Any,N} where N} where P where N where T} where N where T, DenseArray}) where {T<:Union{Complex{Float32}, Complex{Float64}, Float32, Float64}, S} in Base.LinAlg at linalg/matmul.jl:74"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which A' * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.94 KiB\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     88.266 μs (0.00% GC)\n",
       "  median time:      119.130 μs (0.00% GC)\n",
       "  mean time:        123.509 μs (0.00% GC)\n",
       "  maximum time:     375.729 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dispatch to BLAS\n",
    "@benchmark At_mul_B($A, $x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.64 MiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     3.163 ms (0.00% GC)\n",
       "  median time:      3.388 ms (0.00% GC)\n",
       "  mean time:        3.884 ms (21.92% GC)\n",
       "  maximum time:     7.483 ms (41.43% GC)\n",
       "  --------------\n",
       "  samples:          1284\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's force transpose\n",
    "@benchmark transpose($A) * $x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     84.990 μs (0.00% GC)\n",
       "  median time:      118.686 μs (0.00% GC)\n",
       "  mean time:        122.021 μs (0.00% GC)\n",
       "  maximum time:     431.885 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-allocate result\n",
    "out = zeros(size(A, 2))\n",
    "@benchmark At_mul_B!($out, $A, $x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RCall.RObject{RCall.VecSxp}\n",
       "Unit: milliseconds\n",
       "                   expr      min       lq     mean  median      uq      max\n",
       " t(`#JL`$A) %*% `#JL`$x 5.871699 5.986926 6.970327 6.12627 6.43358 11.90592\n",
       " neval\n",
       "   100\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(microbenchmark)\n",
    "microbenchmark(t($A) %*% $x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Broadcasting](https://docs.julialang.org/en/stable/manual/functions/#man-vectorized-1) in Julia achieves vectorized code without creating intermediate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mabs(x::AbstractArray{T}) where T <: Number is deprecated, use abs.(x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mabs\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1m##core#800\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:316\u001b[22m\u001b[22m\n",
      " [4] \u001b[1m##sample#801\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:322\u001b[22m\u001b[22m\n",
      " [5] \u001b[1m#_run#24\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::String, ::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:350\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m(::BenchmarkTools.#kw##_run)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::BenchmarkTools.#_run, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [7] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m./<missing>:?\u001b[22m\u001b[22m\n",
      " [8] \u001b[1m#run_result#19\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:44\u001b[22m\u001b[22m\n",
      " [9] \u001b[1m(::BenchmarkTools.#kw##run_result)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::BenchmarkTools.#run_result, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [10] \u001b[1m#run#21\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:67\u001b[22m\u001b[22m\n",
      " [11] \u001b[1m(::Base.#kw##run)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Base.#run, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [12] \u001b[1mwarmup\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:100\u001b[22m\u001b[22m\n",
      " [13] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m\n",
      " [14] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/Compat/src/Compat.jl:88\u001b[22m\u001b[22m\n",
      " [15] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/IJulia/src/execute_request.jl:180\u001b[22m\u001b[22m\n",
      " [16] \u001b[1m(::Compat.#inner#14{Array{Any,1},IJulia.#execute_request,Tuple{ZMQ.Socket,IJulia.Msg}})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/Compat/src/Compat.jl:332\u001b[22m\u001b[22m\n",
      " [17] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [18] \u001b[1m(::IJulia.##15#18)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[40], in expression starting on line 234\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mabs(x::AbstractArray{T}) where T <: Number is deprecated, use abs.(x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mabs\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1m##core#800\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:316\u001b[22m\u001b[22m\n",
      " [4] \u001b[1m##sample#801\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:322\u001b[22m\u001b[22m\n",
      " [5] \u001b[1m#_run#24\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::String, ::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:350\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m(::BenchmarkTools.#kw##_run)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::BenchmarkTools.#_run, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [7] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m./<missing>:?\u001b[22m\u001b[22m\n",
      " [8] \u001b[1m#run_result#19\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:44\u001b[22m\u001b[22m\n",
      " [9] \u001b[1m(::BenchmarkTools.#kw##run_result)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::BenchmarkTools.#run_result, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [10] \u001b[1m#run#21\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:67\u001b[22m\u001b[22m\n",
      " [11] \u001b[1m(::Base.#kw##run)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Base.#run, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [12] \u001b[1m(::BenchmarkTools.#kw##warmup)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::BenchmarkTools.#warmup, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m\n",
      " [13] \u001b[1m#tune!#26\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::String, ::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:155\u001b[22m\u001b[22m\n",
      " [14] \u001b[1mtune!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:155\u001b[22m\u001b[22m\n",
      " [15] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m\n",
      " [16] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/Compat/src/Compat.jl:88\u001b[22m\u001b[22m\n",
      " [17] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/IJulia/src/execute_request.jl:180\u001b[22m\u001b[22m\n",
      " [18] \u001b[1m(::Compat.#inner#14{Array{Any,1},IJulia.#execute_request,Tuple{ZMQ.Socket,IJulia.Msg}})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/Compat/src/Compat.jl:332\u001b[22m\u001b[22m\n",
      " [19] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [20] \u001b[1m(::IJulia.##15#18)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[40], in expression starting on line 235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  22.92 MiB\n",
       "  allocs estimate:  240\n",
       "  --------------\n",
       "  minimum time:     8.133 ms (21.82% GC)\n",
       "  median time:      8.801 ms (23.11% GC)\n",
       "  mean time:        9.076 ms (23.46% GC)\n",
       "  maximum time:     15.686 ms (12.32% GC)\n",
       "  --------------\n",
       "  samples:          551\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mabs(x::AbstractArray{T}) where T <: Number is deprecated, use abs.(x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mabs\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1m##core#800\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:316\u001b[22m\u001b[22m\n",
      " [4] \u001b[1m##sample#801\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:322\u001b[22m\u001b[22m\n",
      " [5] \u001b[1m#_run#24\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Bool, ::String, ::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:350\u001b[22m\u001b[22m\n",
      " [6] \u001b[1m_run\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:344\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m#run_result#19\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:44\u001b[22m\u001b[22m\n",
      " [8] \u001b[1m#run#21\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}, ::BenchmarkTools.Parameters\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:67\u001b[22m\u001b[22m\n",
      " [9] \u001b[1mrun\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::BenchmarkTools.Benchmark{Symbol(\"##benchmark#799\")}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/BenchmarkTools/src/execution.jl:67\u001b[22m\u001b[22m\n",
      " [10] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m\n",
      " [11] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/Compat/src/Compat.jl:88\u001b[22m\u001b[22m\n",
      " [12] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/IJulia/src/execute_request.jl:180\u001b[22m\u001b[22m\n",
      " [13] \u001b[1m(::Compat.#inner#14{Array{Any,1},IJulia.#execute_request,Tuple{ZMQ.Socket,IJulia.Msg}})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/Compat/src/Compat.jl:332\u001b[22m\u001b[22m\n",
      " [14] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/huazhou/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [15] \u001b[1m(::IJulia.##15#18)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[40], in expression starting on line 236\n"
     ]
    }
   ],
   "source": [
    "srand(123)\n",
    "X, Y = rand(1000,1000), rand(1000,1000)\n",
    "\n",
    "# two temporary arrays are created\n",
    "@benchmark max(abs(X), abs(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.63 MiB\n",
       "  allocs estimate:  27\n",
       "  --------------\n",
       "  minimum time:     2.721 ms (0.00% GC)\n",
       "  median time:      2.961 ms (0.00% GC)\n",
       "  mean time:        3.770 ms (20.88% GC)\n",
       "  maximum time:     7.652 ms (33.75% GC)\n",
       "  --------------\n",
       "  samples:          1325\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no temporary arrays created\n",
    "@benchmark max.(abs.(X), abs.(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     1.551 ms (0.00% GC)\n",
       "  median time:      1.634 ms (0.00% GC)\n",
       "  mean time:        1.719 ms (0.00% GC)\n",
       "  maximum time:     5.972 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2896\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no memory allocation at all!\n",
    "Z = zeros(X)\n",
    "@benchmark $Z .= max.(abs.($X), abs.($Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [View](https://docs.julialang.org/en/stable/stdlib/arrays/#Base.view) avoids creating extra copy of matrix data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  488.45 KiB\n",
       "  allocs estimate:  4\n",
       "  --------------\n",
       "  minimum time:     72.105 μs (0.00% GC)\n",
       "  median time:      328.491 μs (0.00% GC)\n",
       "  mean time:        307.315 μs (15.52% GC)\n",
       "  maximum time:     3.638 ms (87.48% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(123) # seed\n",
    "A = randn(1000, 1000)\n",
    "\n",
    "# sum entries in a sub-matrix\n",
    "@benchmark sum($A[1:2:500, 1:2:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  176 bytes\n",
       "  allocs estimate:  4\n",
       "  --------------\n",
       "  minimum time:     90.750 μs (0.00% GC)\n",
       "  median time:      91.284 μs (0.00% GC)\n",
       "  mean time:        96.048 μs (0.00% GC)\n",
       "  maximum time:     246.577 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view avoids creating a separate sub-matrix\n",
    "@benchmark sum(@view $A[1:2:500, 1:2:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse linear algebra\n",
    "\n",
    "Julia has native support for sparse linear algebra.\n",
    "\n",
    "Generate an n-by-n random sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×500 SparseMatrixCSC{Float64,Int64} with 489 stored entries:\n",
       "  [778 ,    4]  =  -0.673863\n",
       "  [921 ,    5]  =  1.03671\n",
       "  [92  ,    7]  =  1.15882\n",
       "  [397 ,    8]  =  -0.00376628\n",
       "  [798 ,    9]  =  -0.611241\n",
       "  [408 ,   10]  =  1.00541\n",
       "  [532 ,   10]  =  0.848104\n",
       "  [290 ,   11]  =  -0.0717345\n",
       "  [331 ,   11]  =  -0.911516\n",
       "  [473 ,   11]  =  1.39056\n",
       "  ⋮\n",
       "  [784 ,  492]  =  -0.438378\n",
       "  [804 ,  495]  =  0.542732\n",
       "  [567 ,  496]  =  -1.52276\n",
       "  [638 ,  496]  =  0.0264262\n",
       "  [58  ,  497]  =  0.962116\n",
       "  [381 ,  497]  =  -0.15295\n",
       "  [884 ,  497]  =  0.680199\n",
       "  [743 ,  498]  =  0.728707\n",
       "  [382 ,  499]  =  -2.16785\n",
       "  [413 ,  499]  =  -0.248223\n",
       "  [816 ,  500]  =  0.508117"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(123) # seed\n",
    "n, p = 1000, 500\n",
    "A = sprandn(n, p, 0.001) # about 0.1% non-zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison we create the corresponding dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×500 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                      \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Afull = full(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much memory does sparse A take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11872"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base.summarysize(A) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much memory does dense A take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base.summarysize(Afull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-vector multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.94 KiB\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     1.806 μs (0.00% GC)\n",
       "  median time:      2.315 μs (0.00% GC)\n",
       "  mean time:        3.344 μs (18.81% GC)\n",
       "  maximum time:     293.115 μs (97.77% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     10"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = randn(p)\n",
    "@benchmark $A * $b # sparse linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.94 KiB\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     33.890 μs (0.00% GC)\n",
       "  median time:      47.684 μs (0.00% GC)\n",
       "  mean time:        49.562 μs (0.00% GC)\n",
       "  maximum time:     1.408 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark $Afull * $b # dense linear algebra, i.e., BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least squares problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  202.41 KiB\n",
       "  allocs estimate:  105\n",
       "  --------------\n",
       "  minimum time:     184.378 μs (0.00% GC)\n",
       "  median time:      191.375 μs (0.00% GC)\n",
       "  mean time:        217.796 μs (3.65% GC)\n",
       "  maximum time:     3.864 ms (29.20% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = randn(n)\n",
    "@benchmark $A \\ $y # sparse linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  6.13 MiB\n",
       "  allocs estimate:  2455\n",
       "  --------------\n",
       "  minimum time:     19.976 ms (0.00% GC)\n",
       "  median time:      21.649 ms (0.00% GC)\n",
       "  mean time:        22.141 ms (2.30% GC)\n",
       "  maximum time:     27.655 ms (8.12% GC)\n",
       "  --------------\n",
       "  samples:          226\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark $Afull \\ $y # dense linear algebra, i.e., LAPACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative methods for linear algebra\n",
    "\n",
    "Singular value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  773.61 KiB\n",
       "  allocs estimate:  2063\n",
       "  --------------\n",
       "  minimum time:     11.744 ms (0.00% GC)\n",
       "  median time:      13.462 ms (0.00% GC)\n",
       "  mean time:        13.573 ms (0.65% GC)\n",
       "  maximum time:     17.275 ms (15.70% GC)\n",
       "  --------------\n",
       "  samples:          369\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark svds(A) # Lanczos iterative method for top singular values/vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  19.14 MiB\n",
       "  allocs estimate:  20\n",
       "  --------------\n",
       "  minimum time:     71.320 ms (0.00% GC)\n",
       "  median time:      76.612 ms (2.56% GC)\n",
       "  mean time:        76.644 ms (2.58% GC)\n",
       "  maximum time:     81.567 ms (4.26% GC)\n",
       "  --------------\n",
       "  samples:          66\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark svd(Afull) # dense linear algebra, i.e., LAPACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[IterativeSolvers.jl](https://github.com/JuliaMath/IterativeSolvers.jl) package implements many common iterative methods for sparse or more general structured matrices: conjugate gradient (CG), LSQR/LSMR for least squares, ... Combined with [LinearMaps.jl](https://github.com/Jutho/LinearMaps.jl) package, it provides powerful numerial linear algebra engine for structured large arrays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "103px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
