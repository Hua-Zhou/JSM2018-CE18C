{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Nonnegative-Matrix-Factorization---Put-It-Together\" data-toc-modified-id=\"Nonnegative-Matrix-Factorization---Put-It-Together-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Nonnegative Matrix Factorization - Put It Together</a></div><div class=\"lev2 toc-item\"><a href=\"#Nonnegative-Matrix-Factorization\" data-toc-modified-id=\"Nonnegative-Matrix-Factorization-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Nonnegative Matrix Factorization</a></div><div class=\"lev2 toc-item\"><a href=\"#Generate-an-artificial-data-set\" data-toc-modified-id=\"Generate-an-artificial-data-set-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Generate an artificial data set</a></div><div class=\"lev2 toc-item\"><a href=\"#Step-1:-Prototype-code\" data-toc-modified-id=\"Step-1:-Prototype-code-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Step 1: Prototype code</a></div><div class=\"lev2 toc-item\"><a href=\"#Step-2:-Flop-count\" data-toc-modified-id=\"Step-2:-Flop-count-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Step 2: Flop count</a></div><div class=\"lev2 toc-item\"><a href=\"#Step-3:-Memory-management\" data-toc-modified-id=\"Step-3:-Memory-management-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Step 3: Memory management</a></div><div class=\"lev2 toc-item\"><a href=\"#Step-4:-GPU\" data-toc-modified-id=\"Step-4:-GPU-16\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Step 4: GPU</a></div><div class=\"lev3 toc-item\"><a href=\"#Double-precision-on-AMD-Radeon-Pro-460\" data-toc-modified-id=\"Double-precision-on-AMD-Radeon-Pro-460-161\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Double precision on AMD Radeon Pro 460</a></div><div class=\"lev3 toc-item\"><a href=\"#Single-precision-on-AMD-Radeon-Pro-460\" data-toc-modified-id=\"Single-precision-on-AMD-Radeon-Pro-460-162\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Single precision on AMD Radeon Pro 460</a></div><div class=\"lev3 toc-item\"><a href=\"#Single-precision-on-Intel(R)-HD-Graphics-530\" data-toc-modified-id=\"Single-precision-on-Intel(R)-HD-Graphics-530-163\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;</span>Single precision on Intel(R) HD Graphics 530</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonnegative Matrix Factorization - Put It Together\n",
    "\n",
    "In this session, we use techniques (numerical linear algebra, profiling, GPU) we learnt so far to implement the algorithm for nonnegative matrix factorization (NNMF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonnegative Matrix Factorization\n",
    "\n",
    "Nonnegative matrix factorization (NNMF) was introduced by [Lee and Seung (1999)](https://www.nature.com/articles/44565) as an analog of principal components and vector quantization with applications in data compression and clustering.\n",
    "\n",
    "<img src=\"./nnmf.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "In genomics, we can also use NNMF to decompose a genotype matrix $\\mathbf{X}$ (peopole-by-SNPs) as a product of $\\mathbf{V}$ (each row is the population admixture proportions) and $\\mathbf{W}$ (each column is population allele frequences at a specific SNP).\n",
    "\n",
    "In mathematical terms, one approximates a data matrix $\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$ with nonnegative entries $x_{ij}$ by a product of two low-rank matrices $\\mathbf{V} \\in \\mathbb{R}^{m \\times r}$ and $\\mathbf{W} \\in \\mathbb{R}^{r \\times n}$ with nonnegative entries $v_{ik}$ and $w_{kj}$. Consider minimization of the squared Frobenius norm\n",
    "$$\n",
    "\tL(\\mathbf{V}, \\mathbf{W}) = \\|\\mathbf{X} - \\mathbf{V} \\mathbf{W}\\|_{\\text{F}}^2 = \\sum_i \\sum_j \\left(x_{ij} - \\sum_k v_{ik} w_{kj} \\right)^2, \\quad v_{ik} \\ge 0, w_{kj} \\ge 0,\n",
    "$$\n",
    "which should lead to a good factorization. [Lee and Seung (1999)](https://www.nature.com/articles/44565) presents an iterative algorithm with updates\n",
    "$$\n",
    "\tv_{ik}^{(t+1)} = v_{ik}^{(t)} \\frac{\\sum_j x_{ij} w_{kj}^{(t)}}{\\sum_j b_{ij}^{(t)} w_{kj}^{(t)}}, \\quad \\text{where } b_{ij}^{(t)} = \\sum_k v_{ik}^{(t)} w_{kj}^{(t)},\n",
    "$$\n",
    "$$\n",
    "\tw_{kj}^{(t+1)} = w_{kj}^{(t)} \\frac{\\sum_i x_{ij} v_{ik}^{(t+1)}}{\\sum_i b_{ij}^{(t+1/2)} v_{ik}^{(t+1)}}, \\quad \\text{where } b_{ij}^{(t+1/2)} = \\sum_k v_{ik}^{(t+1)} w_{kj}^{(t)}, \n",
    "$$\n",
    "that drive the objective $L^{(t)} = L(\\mathbf{V}^{(t)}, \\mathbf{W}^{(t)})$ downhill. Superscript $t$ indicates iteration number. In matrix notations, the updates are\n",
    "$$\n",
    "    V \\gets V \\,\\, .* \\,\\, (X * W^T) \\,\\, ./ \\,\\, (V * W * W^T)\n",
    "$$\n",
    "$$\n",
    "    W \\gets W \\,\\, .* \\,\\, (V^T * X) \\,\\, ./ \\,\\, (V^T * V * W),\n",
    "$$\n",
    "where $.*$ and $./$ are elementwise multiplication and elementwise division respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an artificial data set\n",
    "\n",
    "We generate a random `X` and aim to fit a rank `r` NNMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srand(123) # seed\n",
    "\n",
    "m, n, r = 2048, 1024, 64\n",
    "X = rand(m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prototype code\n",
    "\n",
    "First let's get something that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nnmf1(\n",
    "    X::Matrix{T},\n",
    "    r::Integer,\n",
    "    maxiter::Integer = 1000,\n",
    "    tolfun::T = 1e-4,\n",
    "    V::Matrix{T} = rand(T, size(X, 1), r),\n",
    "    W::Matrix{T} = rand(T, r, size(X, 2))\n",
    "    ) where T <: AbstractFloat\n",
    "    \n",
    "    # dimensions\n",
    "    m, n = size(X)\n",
    "    obj = vecnorm(X - V * W)^2\n",
    "    # MM loop\n",
    "    for iter in 1:maxiter\n",
    "        V = V .* (X * W') ./ (V * W * W')\n",
    "        W = W .* (V' * X) ./ (V' * V * W)\n",
    "        # convergence check\n",
    "        objold = obj\n",
    "        obj = vecnorm(X - V * W)^2\n",
    "        abs(obj - objold) < tolfun * (abs(objold) + 1) && break\n",
    "    end\n",
    "    # output\n",
    "    return V, W\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consistent timing, we set `tolfun` to 0, use start point of all 1s for `V` and `W`, and let algorithm run for 100 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V0, W0 = ones(m, r), ones(r, n) # start point\n",
    "nnmf1(X, r, 10, 0.0, V0, W0) # warm-up\n",
    "fill!(V0, 1)\n",
    "fill!(W0, 1)\n",
    "@time nnmf1(X, r, 100, 0.0, V0, W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure our code is type stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_warntype nnmf1(X, r, 10, 0.0, V0, W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling to identify computational bottleneck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill!(V0, 1)\n",
    "fill!(W0, 1)\n",
    "Profile.clear()\n",
    "@profile nnmf1(X, r, 100, 0.0, V0, W0)\n",
    "Profile.print(format=:flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Flop count\n",
    "\n",
    "Considering the shapes of `V` and `W`, we realize that `V * W * W'` and `V * (W * W')` have different flop counts. `V * W * W'` has $4mnr$ flops, while `V * (W * W')` needs only $2(m + n)r^2$ flops. This makes a big difference if $r \\ll m, n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nnmf2(\n",
    "    X::Matrix{T},\n",
    "    r::Integer,\n",
    "    maxiter::Integer = 1000,\n",
    "    tolfun::T = 1e-4,\n",
    "    V::Matrix{T} = rand(T, size(X, 1), r),\n",
    "    W::Matrix{T} = rand(T, r, size(X, 2))\n",
    "    ) where T <: AbstractFloat\n",
    "    \n",
    "    # dimensions\n",
    "    m, n = size(X)\n",
    "    obj = vecnorm(X - V * W)^2\n",
    "    # MM loop\n",
    "    for iter in 1:maxiter\n",
    "        V = V .* (X * W') ./ (V * (W * W'))\n",
    "        W = W .* (V' * X) ./ ((V' * V) * W)\n",
    "        # convergence check\n",
    "        objold = obj\n",
    "        obj = vecnorm(X - V * W)^2\n",
    "        abs(obj - objold) < tolfun * (abs(objold) + 1) && break\n",
    "    end\n",
    "    # output\n",
    "    return V, W\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see immediate improvement in run time, memory allocation, and GC time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmf2(X, r, 10, 0.0, V0, W0) # warm-up\n",
    "fill!(V0, 1)\n",
    "fill!(W0, 1)\n",
    "@time nnmf2(X, r, 100, 0.0, V0, W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profile again. We see significant improvement in line 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill!(V0, 1)\n",
    "fill!(W0, 1)\n",
    "Profile.clear()\n",
    "@profile nnmf2(X, r, 100, 0.0, V0, W0)\n",
    "Profile.print(format=:flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Memory management\n",
    "\n",
    "The exessive memory allocation and garbage collection (GC) overhead are worriesome. We observe\n",
    "\n",
    "1. `X * W'` and `W * W'` will actually transpose `W`, causing unnecessary memory allocation.\n",
    "\n",
    "2. Intermediate arrays (`W * W'`, `V' * V`, `V * W`, etc) should be pre-allocated and re-used in loop.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nnmf3(\n",
    "    X::Matrix{T},\n",
    "    r::Integer,\n",
    "    maxiter::Integer=1000,\n",
    "    tolfun::T=1e-4,\n",
    "    V::Matrix{T}=rand(T, size(X, 1), r),\n",
    "    W::Matrix{T}=rand(T, r, size(X, 2))\n",
    "    ) where T <: AbstractFloat\n",
    "    \n",
    "    # dimensions\n",
    "    m, n = size(X)\n",
    "    # pre-allocate arrays\n",
    "    storageV = similar(V) # m-by-r\n",
    "    storageW = similar(W) # r-by-n\n",
    "    storageX = similar(X) # m-by-n\n",
    "    storageR = zeros(eltype(X), r, r) # r-by-r\n",
    "    # start point\n",
    "    A_mul_B!(storageX, V, W)\n",
    "    storageX .= X .- storageX\n",
    "    obj = vecnorm(storageX)^2\n",
    "    # MM loop\n",
    "    for iter in 1:maxiter\n",
    "        # V = V .* (X * W') ./ (V * (W * W'))\n",
    "        A_mul_Bt!(storageR, W, W)\n",
    "        A_mul_B!(storageV, V, storageR)\n",
    "        V .= V ./ storageV\n",
    "        A_mul_Bt!(storageV, X, W)\n",
    "        V .= V .* storageV\n",
    "        # W = W .* (V' * X) ./ ((V' * V) * W)\n",
    "        At_mul_B!(storageR, V, V)\n",
    "        A_mul_B!(storageW, storageR, W)\n",
    "        W .= W ./ storageW\n",
    "        At_mul_B!(storageW, V, X)\n",
    "        W .= W .* storageW\n",
    "        # convergence check\n",
    "        A_mul_B!(storageX, V, W)\n",
    "        objold = obj\n",
    "        storageX .= X .- storageX\n",
    "        obj = vecnorm(storageX)^2\n",
    "        abs(obj - objold) < tolfun * (abs(objold) + 1) && break\n",
    "    end\n",
    "    # output\n",
    "    return V, W\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see huge reduction in memory allocation and GC time is essentially 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmf3(X, r, 10, 0.0, V0, W0) # warm-up\n",
    "fill!(V0, 1)\n",
    "fill!(W0, 1)\n",
    "@time nnmf3(X, r, 100, 0.0, V0, W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profile again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill!(V0, 1)\n",
    "fill!(W0, 1)\n",
    "Profile.clear()\n",
    "@profile nnmf3(X, r, 100, 0.0, V0, W0)\n",
    "Profile.print(format=:flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: GPU\n",
    "\n",
    "**Warning:** this section will not run on the server, which isn't equipped with GPU.\n",
    "\n",
    "Let's inspect available GPU resources on my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GPUArrays, CLArrays\n",
    "\n",
    "# check available devices on this machine\n",
    "mydevices = CLArrays.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duing coding, we found two issues:\n",
    "\n",
    "1. `vecnorm()` doesn't work on GPU.\n",
    "\n",
    "2. `A_mul_Bt!(storageRd, Wd, Wd)` and `At_mul_B!(storageRd, Vd, Vd)` don't work on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nnmf4(\n",
    "    X::Matrix{T},\n",
    "    r::Integer,\n",
    "    dev,\n",
    "    maxiter::Integer=1000,\n",
    "    tolfun::T = 1e-4,\n",
    "    V::Matrix{T} = rand(T, size(X, 1), r),\n",
    "    W::Matrix{T} = rand(T, r, size(X, 2))\n",
    "    ) where T <: AbstractFloat\n",
    "    \n",
    "    # dimensions\n",
    "    m, n = size(X)\n",
    "    # initialize device\n",
    "    ctx = CLArrays.init(dev)\n",
    "    # transfer X, V, W to device\n",
    "    Xd, Vd, Wd = CLArray(X), CLArray(V), CLArray(W)\n",
    "    # pre-allocate arrays on device\n",
    "    storageVd = zeros(CLArray{T}, m, r)\n",
    "    storageWd = zeros(CLArray{T}, r, n)\n",
    "    storageXd = zeros(CLArray{T}, m, n)\n",
    "    storageRd = zeros(CLArray{T}, r, r)\n",
    "    # start point\n",
    "    A_mul_B!(storageXd, Vd, Wd)\n",
    "    storageXd .= Xd .- storageXd\n",
    "    # obj = vecnorm(storageXd)^2 # not working on GPU\n",
    "    obj = sum(abs2, storageXd)\n",
    "    # MM loop\n",
    "    for iter in 1:maxiter\n",
    "        # V = V .* (X * W') ./ (V * (W * W'))\n",
    "        copy!(storageWd, Wd)\n",
    "        A_mul_Bt!(storageRd, Wd, storageWd)\n",
    "        A_mul_B!(storageVd, Vd, storageRd)\n",
    "        Vd .= Vd ./ storageVd\n",
    "        A_mul_Bt!(storageVd, Xd, Wd)\n",
    "        Vd .= Vd .* storageVd\n",
    "        # W = W .* (V' * X) ./ (V' * B)\n",
    "        copy!(storageVd, Vd)\n",
    "        At_mul_B!(storageRd, Vd, storageVd)\n",
    "        A_mul_B!(storageWd, storageRd, Wd)\n",
    "        Wd .= Wd ./ storageWd\n",
    "        At_mul_B!(storageWd, Vd, Xd)\n",
    "        Wd .= Wd .* storageWd\n",
    "        # convergence check\n",
    "        A_mul_B!(storageXd, Vd, Wd)\n",
    "        objold = obj\n",
    "        storageXd .= Xd .- storageXd\n",
    "        # obj = vecnorm(storageXd)^2\n",
    "        obj = sum(abs2, storageXd)\n",
    "        abs(obj - objold) < tolfun * (abs(objold) + 1) && break\n",
    "    end\n",
    "    # collect result from GPU\n",
    "    V = collect(Vd)\n",
    "    W = collect(Wd)\n",
    "    # output    \n",
    "    return V, W\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double precision on AMD Radeon Pro 460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V0, W0 = ones(m, r), ones(r, n) # start point\n",
    "nnmf4(X, r, mydevices[2], 10, 0.0, V0, W0) # warm-up\n",
    "fill!(V0, 1)\n",
    "fill!(W0, 1)\n",
    "@time nnmf4(X, r, mydevices[2], 100, 0.0, V0, W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slower than CPU. But we know that GPU is not good at double precision computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single precision on AMD Radeon Pro 460\n",
    "\n",
    "Let's try single precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsp = Float32.(X)\n",
    "V0sp = ones(Float32, m, r)\n",
    "W0sp = ones(Float32, r, n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmf4(Xsp, r, mydevices[2], 10, Float32(0), V0sp, W0sp) # warm-up\n",
    "fill!(V0sp, 1)\n",
    "fill!(W0sp, 1)\n",
    "@time nnmf4(Xsp, r, mydevices[2], 100, Float32(0), V0sp, W0sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single precision gives slight different answer from double precision, but close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single precision on Intel(R) HD Graphics 530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill!(V0sp, 1)\n",
    "fill!(W0sp, 1)\n",
    "@time nnmf4(Xsp, r, mydevices[1], 100, Float32(0), V0sp, W0sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weaker Intel(R) HD Graphics 530 GPU does not yield much speedup for this example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "629px",
    "left": "0px",
    "right": "1208.872314453125px",
    "top": "105px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
